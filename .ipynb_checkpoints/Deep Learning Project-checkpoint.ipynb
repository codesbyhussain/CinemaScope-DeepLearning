{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "001e3fb3-b43a-4296-a21c-127fba26f24d",
   "metadata": {},
   "source": [
    "# CinemaScope: Automated Sentiment Analysis of IMDb Movie Reviews for Strategic Entertainment Marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a9da89-1106-4325-a7f5-d3321b688316",
   "metadata": {},
   "source": [
    "## Business Problem Statement\n",
    "### Background:\n",
    "In the entertainment industry, especially in film production and distribution, understanding audience sentiment is crucial for both marketing strategies and content creation. Movie reviews, as expressed by viewers on platforms like IMDb, social media, and other review websites, offer a wealth of data that can provide insights into audience preferences and perceptions. However, manually analyzing these reviews is time-consuming, subjective, and inefficient, especially given the volume of data generated with each movie release.\n",
    "\n",
    "### Problem Statement:\n",
    "To enhance strategic decision-making and improve customer engagement, our company seeks to automate the process of sentiment analysis on movie reviews. The goal is to develop a machine learning model that can accurately classify the sentiment of movie reviews as positive or negative. This will enable us to quickly gauge public opinion of new releases, identify shifts in viewer preferences, and adjust marketing strategies accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d060de59-22a5-49a3-aa0f-cf12959fae53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2aa7d130-930d-4934-9b1b-cc4ba7051e0d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Fuction for loading the data\n",
    "def load_data():\n",
    "    # Load the IMDb dataset\n",
    "    (train_data, test_data), info = tfds.load(\n",
    "        'imdb_reviews', \n",
    "        split=['train', 'test'], \n",
    "        as_supervised=True, \n",
    "        with_info=True\n",
    "    )\n",
    "    return train_data, test_data, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ccf720b7-4172-4801-9dca-47fadd4dc319",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "def preprocess_data(train_data, test_data, max_length=256):\n",
    "    # Preprocessing the dataset: convert to padded sequences\n",
    "    train_sentences = []\n",
    "    train_labels = []\n",
    "    \n",
    "    test_sentences = []\n",
    "    test_labels = []\n",
    "    \n",
    "    for s, l in train_data:\n",
    "        train_sentences.append(str(s.numpy().decode('utf8')))\n",
    "        train_labels.append(l.numpy())\n",
    "    \n",
    "    for s, l in test_data:\n",
    "        test_sentences.append(str(s.numpy().decode('utf8')))\n",
    "        test_labels.append(l.numpy())\n",
    "\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token=\"<OOV>\")\n",
    "    tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "    # Convert sentences to sequences\n",
    "    train_sequences = tokenizer.texts_to_sequences(train_sentences)\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_sentences)\n",
    "\n",
    "    # Pad the sequences so they are all the same length\n",
    "    train_padded = pad_sequences(train_sequences, maxlen=max_length, truncating='post')\n",
    "    test_padded = pad_sequences(test_sequences, maxlen=max_length, truncating='post')\n",
    "\n",
    "    # Convert labels to numpy arrays\n",
    "    train_labels = np.array(train_labels)\n",
    "    test_labels = np.array(test_labels)\n",
    "\n",
    "    return train_padded, test_padded, train_labels, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "63efc953-8e63-4c6e-b47c-c77875bfc589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Model Architecture \n",
    "def build_model(vocab_size=10000, embedding_dim=128, rnn_units=64, batch_size=32):\n",
    "    model = Sequential([\n",
    "        Embedding(vocab_size, embedding_dim),\n",
    "        LSTM(rnn_units, return_sequences=True),\n",
    "        LSTM(rnn_units),\n",
    "        Dense(1, activation='sigmoid')\n",
    "    ])\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185c48b-2aeb-46e7-ba4b-548be02901dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_4 (Embedding)     (None, None, 128)         1280000   \n",
      "                                                                 \n",
      " lstm_8 (LSTM)               (None, None, 64)          49408     \n",
      "                                                                 \n",
      " lstm_9 (LSTM)               (None, 64)                33024     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1362497 (5.20 MB)\n",
      "Trainable params: 1362497 (5.20 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n",
      "Epoch 1/5\n",
      "506/782 [==================>...........] - ETA: 1:14 - loss: 0.4546 - accuracy: 0.7828"
     ]
    }
   ],
   "source": [
    "\n",
    "train_data, test_data, info = load_data()\n",
    "train_padded, test_padded, train_labels, test_labels = preprocess_data(train_data, test_data)\n",
    "\n",
    "model = build_model()\n",
    "model.summary()\n",
    "\n",
    "# Train the model\n",
    "history= model.fit(train_padded, train_labels, epochs=5, validation_data=(test_padded, test_labels), verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216b7317-be92-4687-9a71-17af0fd012e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c6b3e7-3369-4190-9e5d-e2976a39c38e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(test_padded, test_labels, verbose=1)\n",
    "print(f\"Loss: {loss}\")\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e65521-45fb-47a9-9b9e-d3fca0eef9ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
